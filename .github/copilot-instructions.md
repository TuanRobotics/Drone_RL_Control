<!-- Autogenerated guidance for AI coding agents working on this repo -->
# Copilot / Agent Instructions for Drone_RL_Control

This file gives focused, practical guidance so an AI coding agent can be immediately productive in this repository.

1) Big picture
- **Purpose:** RL experiments for quadcopter control and drone racing built on PyBullet (see `pyproject.toml` for deps). The repo contains an embedded copy of `gym_pybullet_drones` style environments and example scripts.
- **Major components:**
  - `ppo.py` — local PyTorch PPO/actor implementation snippets (entrypoint for model code). Use as reference for network and distribution conventions.
  - `gym_pybullet_drones/` — main package. Key subpackages:
    - `envs/` — environment implementations (e.g., `BaseAviary.py`, `BaseRLAviary.py`, `HoverAviary.py`, `VelocityAviary.py`). Modify reward/obs here.
    - `control/` — control wrappers (e.g., `BaseControl.py`, `DSLPIDControl.py`, `MRAC.py`). Controllers subclass `BaseControl`.
    - `assets/` — URDF models and related files used by envs.
    - `examples/` — runnable scripts demonstrating training, evaluation, and debugging (`learn.py`, `play.py`, `mrac.py`, `pid.py`). Run these directly from the repo root.
    - `utils/` — helpers (`Logger.py`, `utils.py`, `enums.py`). Look here for common constants and helper functions.

2) Data and runtime flow
- Example flow: `examples/learn.py` -> constructs an `env` from `gym_pybullet_drones.envs` -> env uses `control` to compute actions -> PyBullet loads URDFs from `assets/` and advances simulation.
- Observation / reward shaping is implemented in `envs/*Aviary.py` files. Controllers live in `control/*.py` and provide setpoints/action transforms.

3) Developer workflows & useful commands
- Install dependencies (Poetry recommended): `poetry install` (Python 3.10+). Alternatively create venv and `pip install -r requirements.txt` if you produce one.
- Run tests: `pytest` or `python -m pytest` from repo root. Tests use PyBullet; on headless CI use `xvfb-run -s "-screen 0 1400x900x24" pytest`.
- Run an example: `python examples/learn.py` (or `python examples/play.py`) from the repository root.
- Quick interactive env check:
  - `python -c "from gym_pybullet_drones.envs.CFAviary import CFAviary; env=CFAviary(); obs=env.reset(); print(type(obs))"`

4) Project-specific conventions
- **Controllers:** subclasses of `BaseControl` implement `computeControl`/similar methods. Example: `DSLPIDControl.py`.
- **Env structure:** envs extend `BaseAviary` / `BaseRLAviary`. To change observations, edit `BaseRLAviary` and target aviary files (e.g., `HoverAviary.py`).
- **Assets and URDFs:** models live in `gym_pybullet_drones/assets/`. Tests and envs expect these paths relative to package root.
- **Examples are runnable scripts** (not fully-packaged CLI). Prefer to run them from repo root so relative asset paths resolve.

5) Integration points & external deps
- **PyBullet**: simulation backend — required for envs and tests.
- **Gymnasium**: environment API used by `envs/`.
- **Stable-Baselines3 / Torch**: training code (`ppo.py`, examples) rely on PyTorch and stable-baselines conventions.

6) Editing & testing guidance for agents
- When modifying reward or obs shapes: update the corresponding `*Aviary.py` and run the relevant example (e.g., `examples/learn.py`) and `pytest`.
- When adding a new controller: subclass `BaseControl`, add to `gym_pybullet_drones/control/`, and adapt examples to instantiate it.
- Keep changes minimal and local: follow existing file patterns (do not reorganize package layout unless necessary).

7) Files to inspect first (high signal)
- `gym_pybullet_drones/envs/BaseRLAviary.py` — RL-facing env scaffold
- `gym_pybullet_drones/control/BaseControl.py` — controller base class
- `examples/learn.py` and `examples/play.py` — real usage examples
- `ppo.py` — how model networks are shaped in this project
- `pyproject.toml` — dependency versions and supported Python

If anything in this guidance is unclear or you'd like more examples (e.g., a small run script, or a mapping of tests to functions), tell me which area to expand and I will iterate.
